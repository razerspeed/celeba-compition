{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "resnet-50-celeba.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/razerspeed/celeba-compition/blob/main/resnet_50_celeba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keTM3UAvAf-Y"
      },
      "source": [
        "##Step 0: Downloading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG-PNZOS-fUS"
      },
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O455J8l--Si",
        "outputId": "d3f04c4c-3970-4967-88c4-e1d98b58a9fd"
      },
      "source": [
        "!kaggle datasets download -d jessicali9530/celeba-dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading celeba-dataset.zip to /content\n",
            " 99% 1.32G/1.33G [00:14<00:00, 107MB/s] \n",
            "100% 1.33G/1.33G [00:14<00:00, 97.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK2lwVNf_GYu"
      },
      "source": [
        "!unzip -x  celeba-dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:50.126623Z",
          "iopub.execute_input": "2021-06-05T08:00:50.127007Z",
          "iopub.status.idle": "2021-06-05T08:00:58.484285Z",
          "shell.execute_reply.started": "2021-06-05T08:00:50.126929Z",
          "shell.execute_reply": "2021-06-05T08:00:58.483438Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrSGWO53-dCN",
        "outputId": "9859d17c-15f0-4962-d924-121a479d68ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils ,models\n",
        "from PIL import Image\n",
        "from torch import optim\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrqOD0My_-i9"
      },
      "source": [
        "## Step 1: Loading DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:58.487561Z",
          "iopub.execute_input": "2021-06-05T08:00:58.487823Z",
          "iopub.status.idle": "2021-06-05T08:00:59.214442Z",
          "shell.execute_reply.started": "2021-06-05T08:00:58.487794Z",
          "shell.execute_reply": "2021-06-05T08:00:59.213590Z"
        },
        "trusted": true,
        "id": "zSm0KZ0K-dCS"
      },
      "source": [
        "df = pd.read_csv(\"list_attr_celeba.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.216088Z",
          "iopub.execute_input": "2021-06-05T08:00:59.216423Z",
          "iopub.status.idle": "2021-06-05T08:00:59.250843Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.216389Z",
          "shell.execute_reply": "2021-06-05T08:00:59.249913Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "6pKIrhr9-dCT",
        "outputId": "52f22d7e-8a9e-473d-af66-224135db196d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>5_o_Clock_Shadow</th>\n",
              "      <th>Arched_Eyebrows</th>\n",
              "      <th>Attractive</th>\n",
              "      <th>Bags_Under_Eyes</th>\n",
              "      <th>Bald</th>\n",
              "      <th>Bangs</th>\n",
              "      <th>Big_Lips</th>\n",
              "      <th>Big_Nose</th>\n",
              "      <th>Black_Hair</th>\n",
              "      <th>Blond_Hair</th>\n",
              "      <th>Blurry</th>\n",
              "      <th>Brown_Hair</th>\n",
              "      <th>Bushy_Eyebrows</th>\n",
              "      <th>Chubby</th>\n",
              "      <th>Double_Chin</th>\n",
              "      <th>Eyeglasses</th>\n",
              "      <th>Goatee</th>\n",
              "      <th>Gray_Hair</th>\n",
              "      <th>Heavy_Makeup</th>\n",
              "      <th>High_Cheekbones</th>\n",
              "      <th>Male</th>\n",
              "      <th>Mouth_Slightly_Open</th>\n",
              "      <th>Mustache</th>\n",
              "      <th>Narrow_Eyes</th>\n",
              "      <th>No_Beard</th>\n",
              "      <th>Oval_Face</th>\n",
              "      <th>Pale_Skin</th>\n",
              "      <th>Pointy_Nose</th>\n",
              "      <th>Receding_Hairline</th>\n",
              "      <th>Rosy_Cheeks</th>\n",
              "      <th>Sideburns</th>\n",
              "      <th>Smiling</th>\n",
              "      <th>Straight_Hair</th>\n",
              "      <th>Wavy_Hair</th>\n",
              "      <th>Wearing_Earrings</th>\n",
              "      <th>Wearing_Hat</th>\n",
              "      <th>Wearing_Lipstick</th>\n",
              "      <th>Wearing_Necklace</th>\n",
              "      <th>Wearing_Necktie</th>\n",
              "      <th>Young</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000001.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000002.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000003.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000004.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000005.jpg</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
              "0  000001.jpg                -1                1           1               -1   \n",
              "1  000002.jpg                -1               -1          -1                1   \n",
              "2  000003.jpg                -1               -1          -1               -1   \n",
              "3  000004.jpg                -1               -1           1               -1   \n",
              "4  000005.jpg                -1                1           1               -1   \n",
              "\n",
              "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  Blond_Hair  Blurry  \\\n",
              "0    -1     -1        -1        -1          -1          -1      -1   \n",
              "1    -1     -1        -1         1          -1          -1      -1   \n",
              "2    -1     -1         1        -1          -1          -1       1   \n",
              "3    -1     -1        -1        -1          -1          -1      -1   \n",
              "4    -1     -1         1        -1          -1          -1      -1   \n",
              "\n",
              "   Brown_Hair  Bushy_Eyebrows  Chubby  Double_Chin  Eyeglasses  Goatee  \\\n",
              "0           1              -1      -1           -1          -1      -1   \n",
              "1           1              -1      -1           -1          -1      -1   \n",
              "2          -1              -1      -1           -1          -1      -1   \n",
              "3          -1              -1      -1           -1          -1      -1   \n",
              "4          -1              -1      -1           -1          -1      -1   \n",
              "\n",
              "   Gray_Hair  Heavy_Makeup  High_Cheekbones  Male  Mouth_Slightly_Open  \\\n",
              "0         -1             1                1    -1                    1   \n",
              "1         -1            -1                1    -1                    1   \n",
              "2         -1            -1               -1     1                   -1   \n",
              "3         -1            -1               -1    -1                   -1   \n",
              "4         -1             1               -1    -1                   -1   \n",
              "\n",
              "   Mustache  Narrow_Eyes  No_Beard  Oval_Face  Pale_Skin  Pointy_Nose  \\\n",
              "0        -1           -1         1         -1         -1            1   \n",
              "1        -1           -1         1         -1         -1           -1   \n",
              "2        -1            1         1         -1         -1            1   \n",
              "3        -1           -1         1         -1         -1            1   \n",
              "4        -1            1         1         -1         -1            1   \n",
              "\n",
              "   Receding_Hairline  Rosy_Cheeks  Sideburns  Smiling  Straight_Hair  \\\n",
              "0                 -1           -1         -1        1              1   \n",
              "1                 -1           -1         -1        1             -1   \n",
              "2                 -1           -1         -1       -1             -1   \n",
              "3                 -1           -1         -1       -1              1   \n",
              "4                 -1           -1         -1       -1             -1   \n",
              "\n",
              "   Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
              "0         -1                 1           -1                 1   \n",
              "1         -1                -1           -1                -1   \n",
              "2          1                -1           -1                -1   \n",
              "3         -1                 1           -1                 1   \n",
              "4         -1                -1           -1                 1   \n",
              "\n",
              "   Wearing_Necklace  Wearing_Necktie  Young  \n",
              "0                -1               -1      1  \n",
              "1                -1               -1      1  \n",
              "2                -1               -1      1  \n",
              "3                 1               -1      1  \n",
              "4                -1               -1      1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.252488Z",
          "iopub.execute_input": "2021-06-05T08:00:59.252817Z",
          "iopub.status.idle": "2021-06-05T08:00:59.264682Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.252782Z",
          "shell.execute_reply": "2021-06-05T08:00:59.263907Z"
        },
        "trusted": true,
        "id": "WEdFktNL-dCT"
      },
      "source": [
        "important_feature=df[['image_id','Male','Young']].copy()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.266227Z",
          "iopub.execute_input": "2021-06-05T08:00:59.266837Z",
          "iopub.status.idle": "2021-06-05T08:00:59.270715Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.266797Z",
          "shell.execute_reply": "2021-06-05T08:00:59.269690Z"
        },
        "trusted": true,
        "id": "qCg6earK-dCT"
      },
      "source": [
        "del df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.272192Z",
          "iopub.execute_input": "2021-06-05T08:00:59.272705Z",
          "iopub.status.idle": "2021-06-05T08:00:59.288712Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.272670Z",
          "shell.execute_reply": "2021-06-05T08:00:59.288026Z"
        },
        "trusted": true,
        "id": "GlRycMqZ-dCU"
      },
      "source": [
        "important_feature.replace(-1,0,inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.289820Z",
          "iopub.execute_input": "2021-06-05T08:00:59.290177Z",
          "iopub.status.idle": "2021-06-05T08:00:59.297415Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.290144Z",
          "shell.execute_reply": "2021-06-05T08:00:59.296649Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhedsBdo-dCU",
        "outputId": "55bac405-cd75-477a-9543-341863d0457a"
      },
      "source": [
        "important_feature.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(202599, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ1XG-4RAPTF"
      },
      "source": [
        "## Step 2: Split Dataset into Training, Validation and Test\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.305517Z",
          "iopub.execute_input": "2021-06-05T08:00:59.305984Z",
          "iopub.status.idle": "2021-06-05T08:00:59.312427Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.305948Z",
          "shell.execute_reply": "2021-06-05T08:00:59.311476Z"
        },
        "trusted": true,
        "id": "rryQsvPQ-dCV"
      },
      "source": [
        "train = important_feature.iloc[:50016] \n",
        "val = important_feature.iloc[50017:60033] \n",
        "test = important_feature.iloc[60034:65034]\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:00:59.313579Z",
          "iopub.execute_input": "2021-06-05T08:00:59.314006Z",
          "iopub.status.idle": "2021-06-05T08:00:59.322502Z",
          "shell.execute_reply.started": "2021-06-05T08:00:59.313969Z",
          "shell.execute_reply": "2021-06-05T08:00:59.321436Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsjU9-UC-dCV",
        "outputId": "e5806eca-ec14-45c7-9577-a173dcfc8ecb"
      },
      "source": [
        "print(\"length of train data \", len(train))\n",
        "print(\"length of validataion data \", len(val))\n",
        "print(\"length of test data \", len(test))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of train data  50016\n",
            "length of validataion data  10016\n",
            "length of test data  5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hvF-BVLAzH1"
      },
      "source": [
        "## Step 3: Creating Custom Data Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:00.528693Z",
          "iopub.execute_input": "2021-06-05T08:01:00.529012Z",
          "iopub.status.idle": "2021-06-05T08:01:00.536736Z",
          "shell.execute_reply.started": "2021-06-05T08:01:00.528979Z",
          "shell.execute_reply": "2021-06-05T08:01:00.535546Z"
        },
        "trusted": true,
        "id": "6lLKibts-dCX"
      },
      "source": [
        "class CreateDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data \n",
        "        self.scaler = transforms.Resize([224, 224])\n",
        "        self.normalize = transforms.Normalize(mean=[0.5,0.5,0.5],\n",
        "                                     std=[0.5,0.5,0.5])\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "    def __len__(self):  \n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image_name , male , young = self.data.iloc[idx]\n",
        "        img_loc = 'img_align_celeba/img_align_celeba/'+str(image_name)\n",
        "\n",
        "        img = Image.open(img_loc)\n",
        "        img = self.normalize(self.to_tensor(self.scaler(img)))\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        return image_name, img , torch.tensor([male , young],dtype=torch.float)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:00.538096Z",
          "iopub.execute_input": "2021-06-05T08:01:00.538521Z",
          "iopub.status.idle": "2021-06-05T08:01:00.546816Z",
          "shell.execute_reply.started": "2021-06-05T08:01:00.538486Z",
          "shell.execute_reply": "2021-06-05T08:01:00.545941Z"
        },
        "trusted": true,
        "id": "DU2OPwqp-dCX"
      },
      "source": [
        "train_Dataset = CreateDataset(train)\n",
        "batch_size=32\n",
        "train_Dataloader = DataLoader(train_Dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "val_Dataset = CreateDataset(val)\n",
        "val_Dataloader = DataLoader(val_Dataset, batch_size = batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "test_Dataset = CreateDataset(test)\n",
        "test_Dataloader = DataLoader(test_Dataset, batch_size = 1, shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVMQaoE6BBmc"
      },
      "source": [
        "## Step 4: Downloading and Creating custom Resnet Model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:00.560813Z",
          "iopub.execute_input": "2021-06-05T08:01:00.561125Z",
          "iopub.status.idle": "2021-06-05T08:01:06.825515Z",
          "shell.execute_reply.started": "2021-06-05T08:01:00.561090Z",
          "shell.execute_reply": "2021-06-05T08:01:06.824581Z"
        },
        "trusted": true,
        "id": "efilGLvd-dCY"
      },
      "source": [
        "model=models.resnet50(pretrained= True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXcu1k8lBUzL"
      },
      "source": [
        "**Freezing all the layers in pretrained model**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:06.826775Z",
          "iopub.execute_input": "2021-06-05T08:01:06.827167Z",
          "iopub.status.idle": "2021-06-05T08:01:06.839008Z",
          "shell.execute_reply.started": "2021-06-05T08:01:06.827106Z",
          "shell.execute_reply": "2021-06-05T08:01:06.838245Z"
        },
        "trusted": true,
        "id": "wWqFjhw_-dCY"
      },
      "source": [
        "def freeze(model):\n",
        "    for name, child in model.named_children():\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False\n",
        "        freeze(child)\n",
        "\n",
        "\n",
        "freeze(model)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMg9Rd57Bh_e"
      },
      "source": [
        "**Creating custom Top Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:06.847558Z",
          "iopub.execute_input": "2021-06-05T08:01:06.847947Z",
          "iopub.status.idle": "2021-06-05T08:01:06.857261Z",
          "shell.execute_reply.started": "2021-06-05T08:01:06.847912Z",
          "shell.execute_reply": "2021-06-05T08:01:06.856261Z"
        },
        "trusted": true,
        "id": "f5ZGNDCA-dCY"
      },
      "source": [
        "class CustomResnetModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.fc1 = nn.Linear(in_features=2048, out_features=512)\n",
        "        self.fc2 = nn.Linear(in_features=512, out_features=2)\n",
        "        self.dropout=nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "#         self.identity = nn.Identity()\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        self.model.fc=nn.Identity()\n",
        "        x=self.fc1(self.model(x))\n",
        "        x=self.relu(x)\n",
        "        x=self.dropout(x)\n",
        "        x=self.fc2(x)\n",
        "#         x=self.relu(x)\n",
        "#         x=self.sigmoid(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def weight_init():\n",
        "        for block in custom_model.modules():\n",
        "            if isinstance(block,nn.Linear):\n",
        "                nn.init.kaiming_uniform_(block.weight)\n",
        "                nn.init.constant_(block.bias,1)\n",
        "\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:06.858656Z",
          "iopub.execute_input": "2021-06-05T08:01:06.859110Z",
          "iopub.status.idle": "2021-06-05T08:01:06.874601Z",
          "shell.execute_reply.started": "2021-06-05T08:01:06.859075Z",
          "shell.execute_reply": "2021-06-05T08:01:06.873869Z"
        },
        "trusted": true,
        "id": "YfL9hc4b-dCZ"
      },
      "source": [
        "custom_model=CustomResnetModel()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3qWs7PUCI__"
      },
      "source": [
        "**Collecting all trainable parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:06.945978Z",
          "iopub.execute_input": "2021-06-05T08:01:06.946525Z",
          "iopub.status.idle": "2021-06-05T08:01:06.957813Z",
          "shell.execute_reply.started": "2021-06-05T08:01:06.946481Z",
          "shell.execute_reply": "2021-06-05T08:01:06.957038Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUh9_G1q-dCa",
        "outputId": "6d6460f7-7344-4bf2-b425-7614d08a2270"
      },
      "source": [
        "params_to_update=[]\n",
        "for name,param in custom_model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t fc1.weight\n",
            "\t fc1.bias\n",
            "\t fc2.weight\n",
            "\t fc2.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZI0ZXl1CXgm"
      },
      "source": [
        "**Initializing Loss Function and Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:01:06.958997Z",
          "iopub.execute_input": "2021-06-05T08:01:06.959545Z",
          "iopub.status.idle": "2021-06-05T08:01:11.190439Z",
          "shell.execute_reply.started": "2021-06-05T08:01:06.959507Z",
          "shell.execute_reply": "2021-06-05T08:01:11.189626Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzBNEPtr-dCa",
        "outputId": "3a9dbf23-1a9f-43ef-a2f0-fda343869859"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(params_to_update, lr=0.003)\n",
        "custom_model.to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomResnetModel(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zl2YUgRACzSp"
      },
      "source": [
        "##Step 5 : Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T09:39:41.072238Z",
          "iopub.execute_input": "2021-06-05T09:39:41.072691Z",
          "iopub.status.idle": "2021-06-05T09:39:41.078283Z",
          "shell.execute_reply.started": "2021-06-05T09:39:41.072648Z",
          "shell.execute_reply": "2021-06-05T09:39:41.077437Z"
        },
        "trusted": true,
        "id": "ekn3EDGU-dCb"
      },
      "source": [
        "def accuracy(output,target,batch_size):\n",
        "    output=output.cpu().numpy()\n",
        "    target=target.cpu().numpy()\n",
        "    output=output>0\n",
        "    output.astype(float)\n",
        "    return np.sum(output==target)/(batch_size*2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T08:02:48.534972Z",
          "iopub.execute_input": "2021-06-05T08:02:48.535357Z",
          "iopub.status.idle": "2021-06-05T08:59:04.747488Z",
          "shell.execute_reply.started": "2021-06-05T08:02:48.535322Z",
          "shell.execute_reply": "2021-06-05T08:59:04.746399Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_oAXtGf-dCb",
        "outputId": "0c24c2fc-6bbd-44c0-d631-ec221412b877"
      },
      "source": [
        "import time\n",
        "torch.manual_seed(42)\n",
        "EPOCH=10\n",
        "loss_value_train=[]\n",
        "loss_value_val=[]\n",
        "eval_accuracy=[]\n",
        "min_val_loss=float('inf')\n",
        "for epoch in range(EPOCH):\n",
        "    running_loss=0\n",
        "    epoch_train_loss = []\n",
        "    ### Train Loop\n",
        "    custom_model.train()\n",
        "    t0 = time.time()\n",
        "    t1 = time.time()\n",
        "    print(\"Training ... \")\n",
        "    for i ,data in enumerate(train_Dataloader):\n",
        "        image_name, img ,target = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        img = img.to(device)\n",
        "        \n",
        "        target = target.to(device)\n",
        "\n",
        "\n",
        "        output = custom_model.forward(img)\n",
        "        loss = criterion(output,target)\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        epoch_train_loss.append(loss.item())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        # print statistics\n",
        "        if i % 100 == 99:    # print every 2000 mini-batches\n",
        "            print(f\"[{epoch + 1,i + 1}] loss : {round(running_loss / 100, 3)} time : {round(time.time() - t1,2)} sec\")\n",
        "#             print('[%d, %5d] loss: %.3f time : %' %\n",
        "#                   (epoch + 1, i + 1, running_loss / 20),time.time() - t1)\n",
        "            t1 = time.time()\n",
        "            running_loss = 0.0\n",
        "\n",
        "    print(\"Epoch -> \", epoch,\" Training Loss -> \",\n",
        "          round(sum(epoch_train_loss)/len(train_Dataloader),3),f' time : {round(time.time() - t0,2)} sec')\n",
        "    \n",
        "    loss_value_train.append(sum(epoch_train_loss)/len(train_Dataloader))\n",
        "    \n",
        "    ### Eval Loop\n",
        "    \n",
        "    print(\"Evaluating...\")\n",
        "    \n",
        "    \n",
        "    custom_model.eval()\n",
        "    \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        running_loss=0\n",
        "        epoch_val_loss=[]\n",
        "        running_accuracy=0\n",
        "        \n",
        "        \n",
        "        for i ,data in enumerate(val_Dataloader):\n",
        "            \n",
        "\n",
        "            image_name, img ,target = data\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            img = img.to(device)\n",
        "\n",
        "            target = target.to(device)\n",
        "\n",
        "\n",
        "            output = custom_model.forward(img)\n",
        "            loss = criterion(output,target)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            epoch_val_loss.append(loss.item())\n",
        "            running_accuracy += accuracy(output,target,batch_size)\n",
        "            \n",
        "    total_val_loss=round(sum(epoch_val_loss)/len(val_Dataloader),3)\n",
        "    print(\" Evaluate Loss -> \",\n",
        "          total_val_loss,\" Accuracy --> \",running_accuracy/len(val_Dataloader))\n",
        "    \n",
        "    loss_value_val.append(sum(epoch_val_loss)/len(val_Dataloader))\n",
        "    \n",
        "  \n",
        "    if min_val_loss > total_val_loss:\n",
        "        print(\"Writing Model at epoch \", epoch)\n",
        "        torch.save(custom_model.state_dict(), 'model_state.pth')\n",
        "        min_val_loss = total_val_loss\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training ... \n",
            "[(1, 100)] loss : 0.406 time : 17.76 sec\n",
            "[(1, 200)] loss : 0.345 time : 17.66 sec\n",
            "[(1, 300)] loss : 0.318 time : 17.73 sec\n",
            "[(1, 400)] loss : 0.314 time : 17.88 sec\n",
            "[(1, 500)] loss : 0.308 time : 17.92 sec\n",
            "[(1, 600)] loss : 0.312 time : 18.0 sec\n",
            "[(1, 700)] loss : 0.294 time : 18.02 sec\n",
            "[(1, 800)] loss : 0.3 time : 18.01 sec\n",
            "[(1, 900)] loss : 0.314 time : 17.93 sec\n",
            "[(1, 1000)] loss : 0.302 time : 17.97 sec\n",
            "[(1, 1100)] loss : 0.307 time : 17.99 sec\n",
            "[(1, 1200)] loss : 0.327 time : 17.97 sec\n",
            "[(1, 1300)] loss : 0.32 time : 17.98 sec\n",
            "[(1, 1400)] loss : 0.317 time : 17.93 sec\n",
            "[(1, 1500)] loss : 0.306 time : 17.96 sec\n",
            "Epoch ->  0  Training Loss ->  0.318  time : 280.05 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.271  Accuracy -->  0.8885782747603834\n",
            "Writing Model at epoch  0\n",
            "Training ... \n",
            "[(2, 100)] loss : 0.288 time : 18.07 sec\n",
            "[(2, 200)] loss : 0.294 time : 18.04 sec\n",
            "[(2, 300)] loss : 0.309 time : 17.98 sec\n",
            "[(2, 400)] loss : 0.288 time : 17.92 sec\n",
            "[(2, 500)] loss : 0.287 time : 17.96 sec\n",
            "[(2, 600)] loss : 0.296 time : 17.97 sec\n",
            "[(2, 700)] loss : 0.289 time : 18.0 sec\n",
            "[(2, 800)] loss : 0.309 time : 17.95 sec\n",
            "[(2, 900)] loss : 0.283 time : 17.95 sec\n",
            "[(2, 1000)] loss : 0.289 time : 17.9 sec\n",
            "[(2, 1100)] loss : 0.284 time : 17.98 sec\n",
            "[(2, 1200)] loss : 0.287 time : 17.97 sec\n",
            "[(2, 1300)] loss : 0.294 time : 17.92 sec\n",
            "[(2, 1400)] loss : 0.305 time : 17.95 sec\n",
            "[(2, 1500)] loss : 0.274 time : 17.95 sec\n",
            "Epoch ->  1  Training Loss ->  0.291  time : 280.82 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.27  Accuracy -->  0.884285143769968\n",
            "Writing Model at epoch  1\n",
            "Training ... \n",
            "[(3, 100)] loss : 0.29 time : 17.98 sec\n",
            "[(3, 200)] loss : 0.279 time : 18.01 sec\n",
            "[(3, 300)] loss : 0.283 time : 17.96 sec\n",
            "[(3, 400)] loss : 0.282 time : 17.94 sec\n",
            "[(3, 500)] loss : 0.288 time : 17.96 sec\n",
            "[(3, 600)] loss : 0.288 time : 18.0 sec\n",
            "[(3, 700)] loss : 0.28 time : 18.07 sec\n",
            "[(3, 800)] loss : 0.286 time : 17.93 sec\n",
            "[(3, 900)] loss : 0.291 time : 17.96 sec\n",
            "[(3, 1000)] loss : 0.288 time : 17.94 sec\n",
            "[(3, 1100)] loss : 0.278 time : 17.98 sec\n",
            "[(3, 1200)] loss : 0.277 time : 17.92 sec\n",
            "[(3, 1300)] loss : 0.28 time : 17.97 sec\n",
            "[(3, 1400)] loss : 0.285 time : 18.0 sec\n",
            "[(3, 1500)] loss : 0.29 time : 17.92 sec\n",
            "Epoch ->  2  Training Loss ->  0.285  time : 280.9 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.257  Accuracy -->  0.8915235623003195\n",
            "Writing Model at epoch  2\n",
            "Training ... \n",
            "[(4, 100)] loss : 0.287 time : 18.0 sec\n",
            "[(4, 200)] loss : 0.275 time : 17.92 sec\n",
            "[(4, 300)] loss : 0.275 time : 17.95 sec\n",
            "[(4, 400)] loss : 0.268 time : 17.95 sec\n",
            "[(4, 500)] loss : 0.275 time : 18.11 sec\n",
            "[(4, 600)] loss : 0.283 time : 18.05 sec\n",
            "[(4, 700)] loss : 0.273 time : 17.98 sec\n",
            "[(4, 800)] loss : 0.281 time : 17.98 sec\n",
            "[(4, 900)] loss : 0.276 time : 18.01 sec\n",
            "[(4, 1000)] loss : 0.262 time : 18.08 sec\n",
            "[(4, 1100)] loss : 0.282 time : 17.99 sec\n",
            "[(4, 1200)] loss : 0.278 time : 18.03 sec\n",
            "[(4, 1300)] loss : 0.285 time : 17.95 sec\n",
            "[(4, 1400)] loss : 0.279 time : 18.05 sec\n",
            "[(4, 1500)] loss : 0.258 time : 18.04 sec\n",
            "Epoch ->  3  Training Loss ->  0.276  time : 281.47 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.277  Accuracy -->  0.8808905750798722\n",
            "Training ... \n",
            "[(5, 100)] loss : 0.288 time : 18.02 sec\n",
            "[(5, 200)] loss : 0.267 time : 17.96 sec\n",
            "[(5, 300)] loss : 0.274 time : 17.92 sec\n",
            "[(5, 400)] loss : 0.276 time : 17.96 sec\n",
            "[(5, 500)] loss : 0.282 time : 17.91 sec\n",
            "[(5, 600)] loss : 0.274 time : 17.94 sec\n",
            "[(5, 700)] loss : 0.27 time : 17.92 sec\n",
            "[(5, 800)] loss : 0.281 time : 17.96 sec\n",
            "[(5, 900)] loss : 0.286 time : 17.92 sec\n",
            "[(5, 1000)] loss : 0.277 time : 17.97 sec\n",
            "[(5, 1100)] loss : 0.282 time : 17.94 sec\n",
            "[(5, 1200)] loss : 0.28 time : 17.97 sec\n",
            "[(5, 1300)] loss : 0.28 time : 17.93 sec\n",
            "[(5, 1400)] loss : 0.279 time : 17.95 sec\n",
            "[(5, 1500)] loss : 0.274 time : 17.93 sec\n",
            "Epoch ->  4  Training Loss ->  0.278  time : 280.54 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.261  Accuracy -->  0.8887779552715654\n",
            "Training ... \n",
            "[(6, 100)] loss : 0.283 time : 17.93 sec\n",
            "[(6, 200)] loss : 0.261 time : 17.99 sec\n",
            "[(6, 300)] loss : 0.287 time : 18.03 sec\n",
            "[(6, 400)] loss : 0.262 time : 17.91 sec\n",
            "[(6, 500)] loss : 0.279 time : 17.99 sec\n",
            "[(6, 600)] loss : 0.28 time : 18.15 sec\n",
            "[(6, 700)] loss : 0.279 time : 18.45 sec\n",
            "[(6, 800)] loss : 0.27 time : 18.3 sec\n",
            "[(6, 900)] loss : 0.282 time : 17.97 sec\n",
            "[(6, 1000)] loss : 0.265 time : 17.95 sec\n",
            "[(6, 1100)] loss : 0.266 time : 17.98 sec\n",
            "[(6, 1200)] loss : 0.27 time : 17.94 sec\n",
            "[(6, 1300)] loss : 0.269 time : 17.98 sec\n",
            "[(6, 1400)] loss : 0.29 time : 17.98 sec\n",
            "[(6, 1500)] loss : 0.265 time : 17.9 sec\n",
            "Epoch ->  5  Training Loss ->  0.274  time : 281.76 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.248  Accuracy -->  0.8954672523961661\n",
            "Writing Model at epoch  5\n",
            "Training ... \n",
            "[(7, 100)] loss : 0.277 time : 18.01 sec\n",
            "[(7, 200)] loss : 0.261 time : 17.97 sec\n",
            "[(7, 300)] loss : 0.276 time : 17.9 sec\n",
            "[(7, 400)] loss : 0.275 time : 17.96 sec\n",
            "[(7, 500)] loss : 0.272 time : 17.86 sec\n",
            "[(7, 600)] loss : 0.266 time : 17.93 sec\n",
            "[(7, 700)] loss : 0.275 time : 17.84 sec\n",
            "[(7, 800)] loss : 0.265 time : 17.99 sec\n",
            "[(7, 900)] loss : 0.264 time : 17.98 sec\n",
            "[(7, 1000)] loss : 0.268 time : 17.91 sec\n",
            "[(7, 1100)] loss : 0.272 time : 17.96 sec\n",
            "[(7, 1200)] loss : 0.277 time : 17.95 sec\n",
            "[(7, 1300)] loss : 0.282 time : 18.02 sec\n",
            "[(7, 1400)] loss : 0.27 time : 17.93 sec\n",
            "[(7, 1500)] loss : 0.286 time : 17.96 sec\n",
            "Epoch ->  6  Training Loss ->  0.272  time : 280.49 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.252  Accuracy -->  0.8950179712460063\n",
            "Training ... \n",
            "[(8, 100)] loss : 0.253 time : 17.88 sec\n",
            "[(8, 200)] loss : 0.261 time : 17.9 sec\n",
            "[(8, 300)] loss : 0.27 time : 17.97 sec\n",
            "[(8, 400)] loss : 0.259 time : 17.94 sec\n",
            "[(8, 500)] loss : 0.261 time : 17.88 sec\n",
            "[(8, 600)] loss : 0.279 time : 17.97 sec\n",
            "[(8, 700)] loss : 0.283 time : 17.91 sec\n",
            "[(8, 800)] loss : 0.259 time : 17.92 sec\n",
            "[(8, 900)] loss : 0.284 time : 17.89 sec\n",
            "[(8, 1000)] loss : 0.274 time : 17.9 sec\n",
            "[(8, 1100)] loss : 0.278 time : 17.88 sec\n",
            "[(8, 1200)] loss : 0.274 time : 17.95 sec\n",
            "[(8, 1300)] loss : 0.273 time : 17.96 sec\n",
            "[(8, 1400)] loss : 0.289 time : 17.9 sec\n",
            "[(8, 1500)] loss : 0.278 time : 17.9 sec\n",
            "Epoch ->  7  Training Loss ->  0.271  time : 280.02 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.254  Accuracy -->  0.8950678913738019\n",
            "Training ... \n",
            "[(9, 100)] loss : 0.261 time : 17.88 sec\n",
            "[(9, 200)] loss : 0.261 time : 18.01 sec\n",
            "[(9, 300)] loss : 0.264 time : 17.97 sec\n",
            "[(9, 400)] loss : 0.276 time : 17.88 sec\n",
            "[(9, 500)] loss : 0.282 time : 17.89 sec\n",
            "[(9, 600)] loss : 0.253 time : 17.94 sec\n",
            "[(9, 700)] loss : 0.283 time : 17.9 sec\n",
            "[(9, 800)] loss : 0.259 time : 17.93 sec\n",
            "[(9, 900)] loss : 0.279 time : 18.0 sec\n",
            "[(9, 1000)] loss : 0.266 time : 17.87 sec\n",
            "[(9, 1100)] loss : 0.281 time : 17.96 sec\n",
            "[(9, 1200)] loss : 0.268 time : 17.93 sec\n",
            "[(9, 1300)] loss : 0.258 time : 17.91 sec\n",
            "[(9, 1400)] loss : 0.265 time : 17.9 sec\n",
            "[(9, 1500)] loss : 0.255 time : 17.92 sec\n",
            "Epoch ->  8  Training Loss ->  0.267  time : 280.22 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.257  Accuracy -->  0.8910243610223643\n",
            "Training ... \n",
            "[(10, 100)] loss : 0.261 time : 17.9 sec\n",
            "[(10, 200)] loss : 0.26 time : 17.97 sec\n",
            "[(10, 300)] loss : 0.277 time : 17.91 sec\n",
            "[(10, 400)] loss : 0.251 time : 17.91 sec\n",
            "[(10, 500)] loss : 0.256 time : 17.91 sec\n",
            "[(10, 600)] loss : 0.261 time : 17.97 sec\n",
            "[(10, 700)] loss : 0.252 time : 17.98 sec\n",
            "[(10, 800)] loss : 0.263 time : 17.89 sec\n",
            "[(10, 900)] loss : 0.268 time : 17.89 sec\n",
            "[(10, 1000)] loss : 0.273 time : 17.91 sec\n",
            "[(10, 1100)] loss : 0.271 time : 17.98 sec\n",
            "[(10, 1200)] loss : 0.257 time : 17.89 sec\n",
            "[(10, 1300)] loss : 0.259 time : 17.89 sec\n",
            "[(10, 1400)] loss : 0.274 time : 17.92 sec\n",
            "[(10, 1500)] loss : 0.281 time : 17.93 sec\n",
            "Epoch ->  9  Training Loss ->  0.264  time : 280.18 sec\n",
            "Evaluating...\n",
            " Evaluate Loss ->  0.258  Accuracy -->  0.8891273961661342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4DsS0GxDXTR"
      },
      "source": [
        "**The validation accuracy is around 88.91**\n",
        "\n",
        "**Also the model is saved as model_state.pth**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dg8LJLZDeGj"
      },
      "source": [
        "**Testing accuracy for Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-05T09:40:13.346385Z",
          "iopub.execute_input": "2021-06-05T09:40:13.346732Z",
          "iopub.status.idle": "2021-06-05T09:42:01.727538Z",
          "shell.execute_reply.started": "2021-06-05T09:40:13.346690Z",
          "shell.execute_reply": "2021-06-05T09:42:01.726647Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feQimGOA-dCe",
        "outputId": "4b1c7d70-342a-4a6f-f9d7-12c74306ff2c"
      },
      "source": [
        "custom_model.eval()\n",
        "\n",
        "from tqdm import tqdm\n",
        "with torch.no_grad():\n",
        "    running_loss=0\n",
        "    epoch_val_loss=[]\n",
        "    running_accuracy=0\n",
        "\n",
        "\n",
        "    for data in tqdm(test_Dataloader):\n",
        "\n",
        "        image_name, img ,target = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        img = img.to(device)\n",
        "\n",
        "        target = target.to(device)\n",
        "\n",
        "\n",
        "        output = custom_model.forward(img)\n",
        "\n",
        "        \n",
        "        running_accuracy += accuracy(output,target,1)\n",
        "        \n",
        "        \n",
        "    \n",
        "    print(\" Accuracy --> \",running_accuracy/len(test_Dataloader))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 5000/5000 [00:45<00:00, 110.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy -->  0.8887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kGZrZ5AScNY"
      },
      "source": [
        "\n",
        "**Test accuracy is 88.87**\n",
        "\n"
      ]
    }
  ]
}